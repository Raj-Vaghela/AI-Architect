{
  "tasks": [
    {
      "task_id": "any-to-any",
      "task_label": "Any-to-Any"
    },
    {
      "task_id": "audio-classification",
      "task_label": "Audio Classification"
    }
  ],
  "models": [
    {
      "model_id": "google/gemma-3-27b-it",
      "license": null,
      "likes": 1770,
      "downloads": 1600763,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-27b-pt",
        "base_model:finetune:google/gemma-3-27b-pt",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 1
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "license": null,
      "likes": 596,
      "downloads": 1436041,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-12b-pt",
        "base_model:finetune:google/gemma-3-12b-pt",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 2
    },
    {
      "model_id": "google/gemma-3-4b-it",
      "license": null,
      "likes": 1065,
      "downloads": 854796,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-4b-pt",
        "base_model:finetune:google/gemma-3-4b-pt",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 3
    },
    {
      "model_id": "microsoft/Florence-2-large",
      "license": null,
      "likes": 1725,
      "downloads": 838907,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "florence2",
        "any-to-any",
        "vision",
        "image-text-to-text",
        "custom_code",
        "arxiv:2311.06242",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 4
    },
    {
      "model_id": "OpenGVLab/InternVL3_5-GPT-OSS-20B-A4B-Preview-HF",
      "license": null,
      "likes": 5,
      "downloads": 761249,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "internvl",
        "any-to-any",
        "custom_code",
        "image-text-to-text",
        "conversational",
        "multilingual",
        "dataset:OpenGVLab/MMPR-v1.2",
        "dataset:OpenGVLab/MMPR-Tiny",
        "arxiv:2312.14238",
        "arxiv:2404.16821",
        "arxiv:2412.05271",
        "arxiv:2411.10442",
        "arxiv:2504.10479",
        "arxiv:2508.18265",
        "base_model:OpenGVLab/InternViT-300M-448px-V2_5",
        "base_model:merge:OpenGVLab/InternViT-300M-448px-V2_5",
        "base_model:openai/gpt-oss-20b",
        "base_model:merge:openai/gpt-oss-20b",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 5
    },
    {
      "model_id": "microsoft/Florence-2-base",
      "license": null,
      "likes": 325,
      "downloads": 750585,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "florence2",
        "any-to-any",
        "vision",
        "image-text-to-text",
        "custom_code",
        "arxiv:2311.06242",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 6
    },
    {
      "model_id": "google/medgemma-4b-it",
      "license": null,
      "likes": 803,
      "downloads": 388971,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "medical",
        "radiology",
        "clinical-reasoning",
        "dermatology",
        "pathology",
        "ophthalmology",
        "chest-x-ray",
        "image-text-to-text",
        "conversational",
        "arxiv:2303.15343",
        "arxiv:2507.05201",
        "arxiv:2405.03162",
        "arxiv:2106.14463",
        "arxiv:2412.03555",
        "arxiv:2501.19393",
        "arxiv:2009.13081",
        "arxiv:2102.09542",
        "arxiv:2411.15640",
        "arxiv:2404.05590",
        "arxiv:2501.18362",
        "base_model:google/medgemma-4b-pt",
        "base_model:finetune:google/medgemma-4b-pt",
        "license:other",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 7
    },
    {
      "model_id": "dengcao/GLM-4.1V-9B-Thinking-AWQ",
      "license": null,
      "likes": 1,
      "downloads": 297299,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v",
        "any-to-any",
        "AWQ",
        "vLLM",
        "image-text-to-text",
        "conversational",
        "arxiv:2507.01006",
        "license:mit",
        "endpoints_compatible",
        "4-bit",
        "awq",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 8
    },
    {
      "model_id": "Qwen/Qwen2.5-Omni-3B",
      "license": null,
      "likes": 313,
      "downloads": 261294,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "qwen2_5_omni",
        "multimodal",
        "any-to-any",
        "en",
        "arxiv:2503.20215",
        "license:other",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 9
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "license": null,
      "likes": 1169,
      "downloads": 247321,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "llama4",
        "any-to-any",
        "facebook",
        "meta",
        "pytorch",
        "llama",
        "ar",
        "de",
        "en",
        "es",
        "fr",
        "hi",
        "id",
        "it",
        "pt",
        "th",
        "tl",
        "vi",
        "arxiv:2204.05149",
        "base_model:meta-llama/Llama-4-Scout-17B-16E",
        "base_model:finetune:meta-llama/Llama-4-Scout-17B-16E",
        "license:other",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 10
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "license": null,
      "likes": 779,
      "downloads": 239731,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "qwen3_omni_moe",
        "text-to-audio",
        "multimodal",
        "any-to-any",
        "en",
        "license:other",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 11
    },
    {
      "model_id": "zai-org/GLM-4.1V-9B-Thinking",
      "license": null,
      "likes": 759,
      "downloads": 225845,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v",
        "any-to-any",
        "reasoning",
        "image-text-to-text",
        "conversational",
        "en",
        "zh",
        "arxiv:2507.01006",
        "base_model:zai-org/GLM-4-9B-0414",
        "base_model:finetune:zai-org/GLM-4-9B-0414",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 12
    },
    {
      "model_id": "google/gemma-3n-E2B-it",
      "license": null,
      "likes": 244,
      "downloads": 216356,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3n",
        "any-to-any",
        "automatic-speech-recognition",
        "automatic-speech-translation",
        "audio-text-to-text",
        "video-text-to-text",
        "image-text-to-text",
        "conversational",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2210.03057",
        "arxiv:2502.12404",
        "arxiv:2411.19799",
        "arxiv:2009.03300",
        "arxiv:2502.21228",
        "arxiv:2311.12022",
        "arxiv:2403.07974",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "base_model:google/gemma-3n-E4B-it",
        "base_model:finetune:google/gemma-3n-E4B-it",
        "license:gemma",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 13
    },
    {
      "model_id": "abhishekchohan/gemma-3-12b-it-quantized-W4A16",
      "license": null,
      "likes": 5,
      "downloads": 205690,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "base_model:google/gemma-3-12b-it",
        "base_model:quantized:google/gemma-3-12b-it",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "compressed-tensors",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 14
    },
    {
      "model_id": "zai-org/GLM-4.6V-Flash",
      "license": null,
      "likes": 514,
      "downloads": 203900,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "zh",
        "en",
        "arxiv:2507.01006",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 15
    },
    {
      "model_id": "HuggingFaceTB/SmolVLM2-256M-Video-Instruct",
      "license": null,
      "likes": 89,
      "downloads": 175400,
      "last_modified": "None",
      "tags": [
        "transformers",
        "onnx",
        "safetensors",
        "smolvlm",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "en",
        "dataset:HuggingFaceM4/the_cauldron",
        "dataset:HuggingFaceM4/Docmatix",
        "dataset:lmms-lab/LLaVA-OneVision-Data",
        "dataset:lmms-lab/M4-Instruct-Data",
        "dataset:HuggingFaceFV/finevideo",
        "dataset:MAmmoTH-VL/MAmmoTH-VL-Instruct-12M",
        "dataset:lmms-lab/LLaVA-Video-178K",
        "dataset:orrzohar/Video-STaR",
        "dataset:Mutonix/Vript",
        "dataset:TIGER-Lab/VISTA-400K",
        "dataset:Enxin/MovieChat-1K_train",
        "dataset:ShareGPT4Video/ShareGPT4Video",
        "arxiv:2504.05299",
        "base_model:HuggingFaceTB/SmolVLM-256M-Instruct",
        "base_model:quantized:HuggingFaceTB/SmolVLM-256M-Instruct",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 16
    },
    {
      "model_id": "lmstudio-community/GLM-4.6V-Flash-MLX-4bit",
      "license": null,
      "likes": 1,
      "downloads": 168845,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v",
        "any-to-any",
        "mlx",
        "image-text-to-text",
        "conversational",
        "zh",
        "en",
        "base_model:zai-org/GLM-4.6V-Flash",
        "base_model:quantized:zai-org/GLM-4.6V-Flash",
        "license:mit",
        "endpoints_compatible",
        "4-bit",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 17
    },
    {
      "model_id": "lmstudio-community/GLM-4.6V-Flash-MLX-8bit",
      "license": null,
      "likes": 1,
      "downloads": 167689,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v",
        "any-to-any",
        "mlx",
        "image-text-to-text",
        "conversational",
        "zh",
        "en",
        "base_model:zai-org/GLM-4.6V-Flash",
        "base_model:quantized:zai-org/GLM-4.6V-Flash",
        "license:mit",
        "endpoints_compatible",
        "8-bit",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 18
    },
    {
      "model_id": "Qwen/Qwen2.5-Omni-7B",
      "license": null,
      "likes": 1833,
      "downloads": 166177,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "qwen2_5_omni",
        "multimodal",
        "any-to-any",
        "en",
        "arxiv:2503.20215",
        "license:other",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 19
    },
    {
      "model_id": "lmstudio-community/GLM-4.6V-Flash-MLX-6bit",
      "license": null,
      "likes": 0,
      "downloads": 164282,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v",
        "any-to-any",
        "mlx",
        "image-text-to-text",
        "conversational",
        "zh",
        "en",
        "base_model:zai-org/GLM-4.6V-Flash",
        "base_model:quantized:zai-org/GLM-4.6V-Flash",
        "license:mit",
        "endpoints_compatible",
        "6-bit",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 20
    },
    {
      "model_id": "cyankiwi/GLM-4.6V-AWQ-4bit",
      "license": null,
      "likes": 7,
      "downloads": 133502,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v_moe",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "zh",
        "en",
        "arxiv:2507.01006",
        "base_model:zai-org/GLM-4.6V",
        "base_model:quantized:zai-org/GLM-4.6V",
        "license:mit",
        "endpoints_compatible",
        "compressed-tensors",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 21
    },
    {
      "model_id": "HuggingFaceTB/SmolVLM2-500M-Video-Instruct",
      "license": null,
      "likes": 109,
      "downloads": 123281,
      "last_modified": "None",
      "tags": [
        "transformers",
        "onnx",
        "safetensors",
        "smolvlm",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "en",
        "dataset:HuggingFaceM4/the_cauldron",
        "dataset:HuggingFaceM4/Docmatix",
        "dataset:lmms-lab/LLaVA-OneVision-Data",
        "dataset:lmms-lab/M4-Instruct-Data",
        "dataset:HuggingFaceFV/finevideo",
        "dataset:MAmmoTH-VL/MAmmoTH-VL-Instruct-12M",
        "dataset:lmms-lab/LLaVA-Video-178K",
        "dataset:orrzohar/Video-STaR",
        "dataset:Mutonix/Vript",
        "dataset:TIGER-Lab/VISTA-400K",
        "dataset:Enxin/MovieChat-1K_train",
        "dataset:ShareGPT4Video/ShareGPT4Video",
        "arxiv:2504.05299",
        "base_model:HuggingFaceTB/SmolVLM-500M-Instruct",
        "base_model:quantized:HuggingFaceTB/SmolVLM-500M-Instruct",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 22
    },
    {
      "model_id": "gaunernst/gemma-3-27b-it-int4-awq",
      "license": null,
      "likes": 36,
      "downloads": 123151,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-27b-it",
        "base_model:quantized:google/gemma-3-27b-it",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "4-bit",
        "awq",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 23
    },
    {
      "model_id": "HuggingFaceTB/SmolVLM2-2.2B-Instruct",
      "license": null,
      "likes": 294,
      "downloads": 118061,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "smolvlm",
        "any-to-any",
        "video-text-to-text",
        "image-text-to-text",
        "conversational",
        "en",
        "dataset:HuggingFaceM4/the_cauldron",
        "dataset:HuggingFaceM4/Docmatix",
        "dataset:lmms-lab/LLaVA-OneVision-Data",
        "dataset:lmms-lab/M4-Instruct-Data",
        "dataset:HuggingFaceFV/finevideo",
        "dataset:MAmmoTH-VL/MAmmoTH-VL-Instruct-12M",
        "dataset:lmms-lab/LLaVA-Video-178K",
        "dataset:orrzohar/Video-STaR",
        "dataset:Mutonix/Vript",
        "dataset:TIGER-Lab/VISTA-400K",
        "dataset:Enxin/MovieChat-1K_train",
        "dataset:ShareGPT4Video/ShareGPT4Video",
        "arxiv:2504.05299",
        "base_model:HuggingFaceTB/SmolVLM-Instruct",
        "base_model:finetune:HuggingFaceTB/SmolVLM-Instruct",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 24
    },
    {
      "model_id": "zai-org/GLM-4.6V",
      "license": null,
      "likes": 343,
      "downloads": 110938,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v_moe",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "zh",
        "en",
        "arxiv:2507.01006",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 25
    },
    {
      "model_id": "lmstudio-community/gemma-3n-E4B-it-MLX-4bit",
      "license": null,
      "likes": 1,
      "downloads": 101670,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3n",
        "any-to-any",
        "automatic-speech-recognition",
        "automatic-speech-translation",
        "audio-text-to-text",
        "video-text-to-text",
        "mlx",
        "image-text-to-text",
        "conversational",
        "base_model:google/gemma-3n-E4B-it",
        "base_model:quantized:google/gemma-3n-E4B-it",
        "license:gemma",
        "endpoints_compatible",
        "4-bit",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 26
    },
    {
      "model_id": "unsloth/gemma-3-12b-it-unsloth-bnb-4bit",
      "license": null,
      "likes": 24,
      "downloads": 100960,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "unsloth",
        "gemma",
        "google",
        "en",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-12b-it",
        "base_model:quantized:google/gemma-3-12b-it",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "4-bit",
        "bitsandbytes",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 27
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "license": null,
      "likes": 441,
      "downloads": 99382,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "llama4",
        "any-to-any",
        "facebook",
        "meta",
        "pytorch",
        "llama",
        "ar",
        "de",
        "en",
        "es",
        "fr",
        "hi",
        "id",
        "it",
        "pt",
        "th",
        "tl",
        "vi",
        "arxiv:2204.05149",
        "base_model:meta-llama/Llama-4-Maverick-17B-128E",
        "base_model:finetune:meta-llama/Llama-4-Maverick-17B-128E",
        "license:other",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 28
    },
    {
      "model_id": "lmstudio-community/gemma-3n-E4B-it-MLX-bf16",
      "license": null,
      "likes": 3,
      "downloads": 99193,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3n",
        "any-to-any",
        "automatic-speech-recognition",
        "automatic-speech-translation",
        "audio-text-to-text",
        "video-text-to-text",
        "mlx",
        "image-text-to-text",
        "conversational",
        "base_model:google/gemma-3n-E4B-it",
        "base_model:finetune:google/gemma-3n-E4B-it",
        "license:gemma",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 29
    },
    {
      "model_id": "openbmb/MiniCPM-o-2_6",
      "license": null,
      "likes": 1273,
      "downloads": 99106,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "minicpmo",
        "feature-extraction",
        "minicpm-o",
        "omni",
        "vision",
        "ocr",
        "multi-image",
        "video",
        "custom_code",
        "audio",
        "speech",
        "voice cloning",
        "live Streaming",
        "realtime speech conversation",
        "asr",
        "tts",
        "any-to-any",
        "multilingual",
        "dataset:openbmb/RLAIF-V-Dataset",
        "arxiv:2405.17220",
        "arxiv:2408.01800",
        "license:apache-2.0",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 30
    },
    {
      "model_id": "lmstudio-community/gemma-3n-E4B-it-MLX-8bit",
      "license": null,
      "likes": 0,
      "downloads": 99029,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3n",
        "any-to-any",
        "automatic-speech-recognition",
        "automatic-speech-translation",
        "audio-text-to-text",
        "video-text-to-text",
        "mlx",
        "image-text-to-text",
        "conversational",
        "base_model:google/gemma-3n-E4B-it",
        "base_model:quantized:google/gemma-3n-E4B-it",
        "license:gemma",
        "endpoints_compatible",
        "8-bit",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 31
    },
    {
      "model_id": "lmstudio-community/gemma-3n-E4B-it-MLX-6bit",
      "license": null,
      "likes": 0,
      "downloads": 98668,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3n",
        "any-to-any",
        "automatic-speech-recognition",
        "automatic-speech-translation",
        "audio-text-to-text",
        "video-text-to-text",
        "mlx",
        "image-text-to-text",
        "conversational",
        "base_model:google/gemma-3n-E4B-it",
        "base_model:quantized:google/gemma-3n-E4B-it",
        "license:gemma",
        "endpoints_compatible",
        "6-bit",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 32
    },
    {
      "model_id": "OpenGVLab/InternVL3-1B-hf",
      "license": null,
      "likes": 10,
      "downloads": 91149,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "internvl",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "multilingual",
        "dataset:OpenGVLab/MMPR-v1.2",
        "arxiv:2312.14238",
        "arxiv:2404.16821",
        "arxiv:2412.05271",
        "arxiv:2411.10442",
        "arxiv:2504.10479",
        "base_model:OpenGVLab/InternVL3-1B-Instruct",
        "base_model:finetune:OpenGVLab/InternVL3-1B-Instruct",
        "license:other",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 33
    },
    {
      "model_id": "unsloth/gemma-3-4b-it",
      "license": null,
      "likes": 22,
      "downloads": 88559,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "unsloth",
        "image-text-to-text",
        "conversational",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-4b-it",
        "base_model:finetune:google/gemma-3-4b-it",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 34
    },
    {
      "model_id": "google/gemma-3n-E4B-it",
      "license": null,
      "likes": 837,
      "downloads": 87969,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3n",
        "any-to-any",
        "automatic-speech-recognition",
        "automatic-speech-translation",
        "audio-text-to-text",
        "video-text-to-text",
        "image-text-to-text",
        "conversational",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2210.03057",
        "arxiv:2502.12404",
        "arxiv:2411.19799",
        "arxiv:2009.03300",
        "arxiv:2502.21228",
        "arxiv:2311.12022",
        "arxiv:2403.07974",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "base_model:google/gemma-3n-E4B",
        "base_model:finetune:google/gemma-3n-E4B",
        "license:gemma",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 35
    },
    {
      "model_id": "mlx-community/gemma-3-12b-it-qat-4bit",
      "license": null,
      "likes": 17,
      "downloads": 86584,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "internvl",
        "custom_code",
        "mlx",
        "image-text-to-text",
        "conversational",
        "multilingual",
        "dataset:OpenGVLab/MMPR-v1.2",
        "base_model:OpenGVLab/InternVL3-1B-Instruct",
        "base_model:finetune:OpenGVLab/InternVL3-1B-Instruct",
        "license:other",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 36
    },
    {
      "model_id": "zai-org/AutoGLM-Phone-9B",
      "license": null,
      "likes": 390,
      "downloads": 76130,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "glm4v",
        "any-to-any",
        "agent",
        "image-text-to-text",
        "conversational",
        "zh",
        "arxiv:2411.00820",
        "arxiv:2509.18119",
        "base_model:zai-org/GLM-4.1V-9B-Base",
        "base_model:finetune:zai-org/GLM-4.1V-9B-Base",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 37
    },
    {
      "model_id": "unsloth/gemma-3-27b-it-bnb-4bit",
      "license": null,
      "likes": 18,
      "downloads": 73637,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "unsloth",
        "gemma",
        "google",
        "en",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-27b-it",
        "base_model:quantized:google/gemma-3-27b-it",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "4-bit",
        "bitsandbytes",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 38
    },
    {
      "model_id": "mlx-community/gemma-3-27b-it-qat-4bit",
      "license": null,
      "likes": 20,
      "downloads": 68095,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "internvl",
        "custom_code",
        "mlx",
        "image-text-to-text",
        "conversational",
        "multilingual",
        "dataset:OpenGVLab/MMPR-v1.2",
        "base_model:OpenGVLab/InternVL3-1B-Instruct",
        "base_model:finetune:OpenGVLab/InternVL3-1B-Instruct",
        "license:other",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 39
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "license": null,
      "likes": 144,
      "downloads": 67186,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "llama4",
        "any-to-any",
        "facebook",
        "meta",
        "pytorch",
        "llama",
        "ar",
        "de",
        "en",
        "es",
        "fr",
        "hi",
        "id",
        "it",
        "pt",
        "th",
        "tl",
        "vi",
        "arxiv:2204.05149",
        "base_model:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "base_model:quantized:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "license:other",
        "text-generation-inference",
        "endpoints_compatible",
        "compressed-tensors",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 40
    },
    {
      "model_id": "meta-llama/Llama-Guard-4-12B",
      "license": null,
      "likes": 68,
      "downloads": 66576,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "llama4",
        "any-to-any",
        "facebook",
        "meta",
        "pytorch",
        "llama",
        "safety",
        "en",
        "arxiv:2503.05731",
        "arxiv:2407.21783",
        "license:other",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 41
    },
    {
      "model_id": "deepseek-ai/Janus-Pro-7B",
      "license": null,
      "likes": 3543,
      "downloads": 66189,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "multi_modality",
        "muiltimodal",
        "text-to-image",
        "unified-model",
        "any-to-any",
        "arxiv:2501.17811",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 42
    },
    {
      "model_id": "RioJune/AG-KD",
      "license": null,
      "likes": 0,
      "downloads": 64969,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "florence2",
        "any-to-any",
        "zero-shot-object-detection",
        "custom_code",
        "arxiv:2508.04572",
        "arxiv:2503.03278",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "zero-shot-object-detection",
      "task_id": "any-to-any",
      "rank_in_task": 43
    },
    {
      "model_id": "trl-internal-testing/tiny-Gemma3ForConditionalGeneration",
      "license": null,
      "likes": 0,
      "downloads": 63399,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "trl",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 44
    },
    {
      "model_id": "unsloth/gemma-3-27b-it-GGUF",
      "license": null,
      "likes": 178,
      "downloads": 58853,
      "last_modified": "None",
      "tags": [
        "transformers",
        "gguf",
        "gemma3",
        "any-to-any",
        "unsloth",
        "gemma",
        "google",
        "en",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-27b-it",
        "base_model:quantized:google/gemma-3-27b-it",
        "license:gemma",
        "endpoints_compatible",
        "region:us",
        "imatrix",
        "conversational"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 45
    },
    {
      "model_id": "unsloth/gemma-3-4b-it-GGUF",
      "license": null,
      "likes": 158,
      "downloads": 56412,
      "last_modified": "None",
      "tags": [
        "transformers",
        "gguf",
        "gemma3",
        "any-to-any",
        "unsloth",
        "gemma",
        "google",
        "en",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "base_model:google/gemma-3-4b-it",
        "base_model:quantized:google/gemma-3-4b-it",
        "license:gemma",
        "endpoints_compatible",
        "region:us",
        "conversational"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 46
    },
    {
      "model_id": "florence-community/Florence-2-large-ft",
      "license": null,
      "likes": 4,
      "downloads": 55930,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "florence2",
        "any-to-any",
        "vision",
        "image-text-to-text",
        "arxiv:2311.06242",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 47
    },
    {
      "model_id": "CohereLabs/aya-vision-8b",
      "license": null,
      "likes": 316,
      "downloads": 51709,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "aya_vision",
        "any-to-any",
        "image-text-to-text",
        "conversational",
        "en",
        "fr",
        "de",
        "es",
        "it",
        "pt",
        "ja",
        "ko",
        "zh",
        "ar",
        "el",
        "fa",
        "pl",
        "id",
        "cs",
        "he",
        "hi",
        "nl",
        "ro",
        "ru",
        "tr",
        "uk",
        "vi",
        "arxiv:2412.04261",
        "license:cc-by-nc-4.0",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 48
    },
    {
      "model_id": "google/gemma-3-4b-pt",
      "license": null,
      "likes": 130,
      "downloads": 51082,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "gemma3",
        "any-to-any",
        "image-text-to-text",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1911.11641",
        "arxiv:1904.09728",
        "arxiv:1705.03551",
        "arxiv:1911.01547",
        "arxiv:1907.10641",
        "arxiv:1903.00161",
        "arxiv:2009.03300",
        "arxiv:2304.06364",
        "arxiv:2103.03874",
        "arxiv:2110.14168",
        "arxiv:2311.12022",
        "arxiv:2108.07732",
        "arxiv:2107.03374",
        "arxiv:2210.03057",
        "arxiv:2106.03193",
        "arxiv:1910.11856",
        "arxiv:2502.12404",
        "arxiv:2502.21228",
        "arxiv:2404.16816",
        "arxiv:2104.12756",
        "arxiv:2311.16502",
        "arxiv:2203.10244",
        "arxiv:2404.12390",
        "arxiv:1810.12440",
        "arxiv:1908.02660",
        "arxiv:2312.11805",
        "license:gemma",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "image-text-to-text",
      "task_id": "any-to-any",
      "rank_in_task": 49
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
      "license": null,
      "likes": 240,
      "downloads": 48001,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "qwen3_omni_moe",
        "text-to-audio",
        "multimodal",
        "any-to-any",
        "en",
        "license:other",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "any-to-any",
      "task_id": "any-to-any",
      "rank_in_task": 50
    },
    {
      "model_id": "speechbrain/emotion-recognition-wav2vec2-IEMOCAP",
      "license": null,
      "likes": 168,
      "downloads": 680235,
      "last_modified": "None",
      "tags": [
        "speechbrain",
        "audio-classification",
        "Emotion",
        "Recognition",
        "wav2vec2",
        "pytorch",
        "en",
        "dataset:iemocap",
        "arxiv:2106.04624",
        "license:apache-2.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 1
    },
    {
      "model_id": "audeering/wav2vec2-large-robust-24-ft-age-gender",
      "license": null,
      "likes": 48,
      "downloads": 663025,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "wav2vec2",
        "speech",
        "audio",
        "audio-classification",
        "age-recognition",
        "gender-recognition",
        "dataset:agender",
        "dataset:mozillacommonvoice",
        "dataset:timit",
        "dataset:voxceleb2",
        "arxiv:2306.16962",
        "base_model:facebook/wav2vec2-large-robust",
        "base_model:finetune:facebook/wav2vec2-large-robust",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 2
    },
    {
      "model_id": "audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim",
      "license": null,
      "likes": 145,
      "downloads": 520805,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "wav2vec2",
        "speech",
        "audio",
        "audio-classification",
        "emotion-recognition",
        "en",
        "dataset:msp-podcast",
        "arxiv:2203.07378",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 3
    },
    {
      "model_id": "MIT/ast-finetuned-audioset-10-10-0.4593",
      "license": null,
      "likes": 333,
      "downloads": 338990,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "audio-spectrogram-transformer",
        "audio-classification",
        "arxiv:2104.01778",
        "license:bsd-3-clause",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 4
    },
    {
      "model_id": "MIT/ast-finetuned-audioset-14-14-0.443",
      "license": null,
      "likes": 6,
      "downloads": 286838,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "audio-spectrogram-transformer",
        "audio-classification",
        "arxiv:2104.01778",
        "license:bsd-3-clause",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 5
    },
    {
      "model_id": "OpenMuQ/MuQ-large-msd-iter",
      "license": null,
      "likes": 14,
      "downloads": 268248,
      "last_modified": "None",
      "tags": [
        "pytorch",
        "safetensors",
        "music",
        "audio-classification",
        "en",
        "zh",
        "arxiv:2501.01108",
        "license:cc-by-nc-4.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 6
    },
    {
      "model_id": "xbgoose/hubert-large-speech-emotion-recognition-russian-dusha-finetuned",
      "license": null,
      "likes": 13,
      "downloads": 237688,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "hubert",
        "audio-classification",
        "SER",
        "speech",
        "audio",
        "russian",
        "ru",
        "dataset:xbgoose/dusha",
        "base_model:facebook/hubert-large-ls960-ft",
        "base_model:finetune:facebook/hubert-large-ls960-ft",
        "license:apache-2.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 7
    },
    {
      "model_id": "speechbrain/spkrec-xvect-voxceleb",
      "license": null,
      "likes": 64,
      "downloads": 169466,
      "last_modified": "None",
      "tags": [
        "speechbrain",
        "embeddings",
        "Speaker",
        "Verification",
        "Identification",
        "pytorch",
        "xvectors",
        "TDNN",
        "audio-classification",
        "en",
        "dataset:voxceleb",
        "arxiv:2106.04624",
        "license:apache-2.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 8
    },
    {
      "model_id": "facebook/audiobox-aesthetics",
      "license": null,
      "likes": 41,
      "downloads": 159127,
      "last_modified": "None",
      "tags": [
        "safetensors",
        "model_hub_mixin",
        "pytorch_model_hub_mixin",
        "audio-classification",
        "arxiv:2502.05139",
        "license:cc-by-4.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 9
    },
    {
      "model_id": "sanchit-gandhi/distilhubert-finetuned-gtzan",
      "license": null,
      "likes": 3,
      "downloads": 156771,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "tensorboard",
        "safetensors",
        "hubert",
        "audio-classification",
        "generated_from_trainer",
        "dataset:marsyas/gtzan",
        "license:apache-2.0",
        "model-index",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 10
    },
    {
      "model_id": "facebook/mms-lid-126",
      "license": null,
      "likes": 33,
      "downloads": 125335,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "mms",
        "ab",
        "af",
        "ak",
        "am",
        "ar",
        "as",
        "av",
        "ay",
        "az",
        "ba",
        "bm",
        "be",
        "bn",
        "bi",
        "bo",
        "sh",
        "br",
        "bg",
        "ca",
        "cs",
        "ce",
        "cv",
        "ku",
        "cy",
        "da",
        "de",
        "dv",
        "dz",
        "el",
        "en",
        "eo",
        "et",
        "eu",
        "ee",
        "fo",
        "fa",
        "fj",
        "fi",
        "fr",
        "fy",
        "ff",
        "ga",
        "gl",
        "gn",
        "gu",
        "zh",
        "ht",
        "ha",
        "he",
        "hi",
        "hu",
        "hy",
        "ig",
        "ia",
        "ms",
        "is",
        "it",
        "jv",
        "ja",
        "kn",
        "ka",
        "kk",
        "kr",
        "km",
        "ki",
        "rw",
        "ky",
        "ko",
        "kv",
        "lo",
        "la",
        "lv",
        "ln",
        "lt",
        "lb",
        "lg",
        "mh",
        "ml",
        "mr",
        "mk",
        "mg",
        "mt",
        "mn",
        "mi",
        "my",
        "nl",
        "no",
        "ne",
        "ny",
        "oc",
        "om",
        "or",
        "os",
        "pa",
        "pl",
        "pt",
        "ps",
        "qu",
        "ro",
        "rn",
        "ru",
        "sg",
        "sk",
        "sl",
        "sm",
        "sn",
        "sd",
        "so",
        "es",
        "sq",
        "su",
        "sv",
        "sw",
        "ta",
        "tt",
        "te",
        "tg",
        "tl",
        "th",
        "ti",
        "ts",
        "tr",
        "uk",
        "vi",
        "wo",
        "xh",
        "yo",
        "zu",
        "za",
        "dataset:google/fleurs",
        "arxiv:2305.13516",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 11
    },
    {
      "model_id": "prithivMLmods/Common-Voice-Gender-Detection",
      "license": null,
      "likes": 16,
      "downloads": 121564,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "voice-gender-detection",
        "male",
        "female",
        "biology",
        "SFT",
        "en",
        "arxiv:2006.11477",
        "base_model:facebook/wav2vec2-base-960h",
        "base_model:finetune:facebook/wav2vec2-base-960h",
        "doi:10.57967/hf/5684",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 12
    },
    {
      "model_id": "speechbrain/lang-id-voxlingua107-ecapa",
      "license": null,
      "likes": 137,
      "downloads": 114423,
      "last_modified": "None",
      "tags": [
        "speechbrain",
        "audio-classification",
        "embeddings",
        "Language",
        "Identification",
        "pytorch",
        "ECAPA-TDNN",
        "TDNN",
        "VoxLingua107",
        "multilingual",
        "ab",
        "af",
        "am",
        "ar",
        "as",
        "az",
        "ba",
        "be",
        "bg",
        "bi",
        "bo",
        "br",
        "bs",
        "ca",
        "ceb",
        "cs",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "eo",
        "es",
        "et",
        "eu",
        "fa",
        "fi",
        "fo",
        "fr",
        "gl",
        "gn",
        "gu",
        "gv",
        "ha",
        "haw",
        "hi",
        "hr",
        "ht",
        "hu",
        "hy",
        "ia",
        "id",
        "is",
        "it",
        "he",
        "ja",
        "jv",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "la",
        "lm",
        "ln",
        "lo",
        "lt",
        "lv",
        "mg",
        "mi",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "mt",
        "my",
        "ne",
        "nl",
        "nn",
        "no",
        "oc",
        "pa",
        "pl",
        "ps",
        "pt",
        "ro",
        "ru",
        "sa",
        "sco",
        "sd",
        "si",
        "sk",
        "sl",
        "sn",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "tg",
        "th",
        "tk",
        "tl",
        "tr",
        "tt",
        "uk",
        "ud",
        "uz",
        "vi",
        "war",
        "yi",
        "yo",
        "zh",
        "dataset:VoxLingua107",
        "arxiv:2106.04624",
        "license:apache-2.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 13
    },
    {
      "model_id": "m-a-p/MERT-v1-95M",
      "license": null,
      "likes": 40,
      "downloads": 109099,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "mert_model",
        "feature-extraction",
        "music",
        "audio-classification",
        "custom_code",
        "arxiv:2306.00107",
        "license:cc-by-nc-4.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 14
    },
    {
      "model_id": "audeering/wav2vec2-large-robust-6-ft-age-gender",
      "license": null,
      "likes": 3,
      "downloads": 65008,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "wav2vec2",
        "speech",
        "audio",
        "audio-classification",
        "age-recognition",
        "gender-recognition",
        "dataset:agender",
        "dataset:mozillacommonvoice",
        "dataset:timit",
        "dataset:voxceleb2",
        "arxiv:2306.16962",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 15
    },
    {
      "model_id": "facebook/mms-lid-256",
      "license": null,
      "likes": 15,
      "downloads": 63048,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "mms",
        "ab",
        "af",
        "ak",
        "am",
        "ar",
        "as",
        "av",
        "ay",
        "az",
        "ba",
        "bm",
        "be",
        "bn",
        "bi",
        "bo",
        "sh",
        "br",
        "bg",
        "ca",
        "cs",
        "ce",
        "cv",
        "ku",
        "cy",
        "da",
        "de",
        "dv",
        "dz",
        "el",
        "en",
        "eo",
        "et",
        "eu",
        "ee",
        "fo",
        "fa",
        "fj",
        "fi",
        "fr",
        "fy",
        "ff",
        "ga",
        "gl",
        "gn",
        "gu",
        "zh",
        "ht",
        "ha",
        "he",
        "hi",
        "hu",
        "hy",
        "ig",
        "ia",
        "ms",
        "is",
        "it",
        "jv",
        "ja",
        "kn",
        "ka",
        "kk",
        "kr",
        "km",
        "ki",
        "rw",
        "ky",
        "ko",
        "kv",
        "lo",
        "la",
        "lv",
        "ln",
        "lt",
        "lb",
        "lg",
        "mh",
        "ml",
        "mr",
        "mk",
        "mg",
        "mt",
        "mn",
        "mi",
        "my",
        "nl",
        "no",
        "ne",
        "ny",
        "oc",
        "om",
        "or",
        "os",
        "pa",
        "pl",
        "pt",
        "ps",
        "qu",
        "ro",
        "rn",
        "ru",
        "sg",
        "sk",
        "sl",
        "sm",
        "sn",
        "sd",
        "so",
        "es",
        "sq",
        "su",
        "sv",
        "sw",
        "ta",
        "tt",
        "te",
        "tg",
        "tl",
        "th",
        "ti",
        "ts",
        "tr",
        "uk",
        "vi",
        "wo",
        "xh",
        "yo",
        "zu",
        "za",
        "dataset:google/fleurs",
        "arxiv:2305.13516",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 16
    },
    {
      "model_id": "OpenMuQ/MuQ-MuLan-large",
      "license": null,
      "likes": 13,
      "downloads": 59925,
      "last_modified": "None",
      "tags": [
        "pytorch",
        "music",
        "audio-classification",
        "en",
        "zh",
        "arxiv:2501.01108",
        "license:cc-by-nc-4.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 17
    },
    {
      "model_id": "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
      "license": null,
      "likes": 237,
      "downloads": 53322,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "tensorboard",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "generated_from_trainer",
        "doi:10.57967/hf/2045",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 18
    },
    {
      "model_id": "JaesungHuh/voice-gender-classifier",
      "license": null,
      "likes": 30,
      "downloads": 46287,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "pytorch_model_hub_mixin",
        "model_hub_mixin",
        "gender-classification",
        "VoxCeleb",
        "audio-classification",
        "dataset:ProgramComputer/voxceleb",
        "arxiv:2005.07143",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 19
    },
    {
      "model_id": "superb/wav2vec2-base-superb-er",
      "license": null,
      "likes": 14,
      "downloads": 32967,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "wav2vec2",
        "audio-classification",
        "speech",
        "audio",
        "en",
        "dataset:superb",
        "arxiv:2105.01051",
        "license:apache-2.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 20
    },
    {
      "model_id": "firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3",
      "license": null,
      "likes": 99,
      "downloads": 26951,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "whisper",
        "audio-classification",
        "generated_from_trainer",
        "base_model:openai/whisper-large-v3",
        "base_model:finetune:openai/whisper-large-v3",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 21
    },
    {
      "model_id": "3loi/SER-Odyssey-Baseline-WavLM-Multi-Attributes",
      "license": null,
      "likes": 9,
      "downloads": 24204,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "ser",
        "audio-classification",
        "wavlm",
        "msp-podcast",
        "emotion-recognition",
        "audio",
        "speech",
        "valence",
        "arousal",
        "dominance",
        "lucas",
        "speech-emotion-recognition",
        "custom_code",
        "en",
        "license:mit",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 22
    },
    {
      "model_id": "m-a-p/MERT-v1-330M",
      "license": null,
      "likes": 80,
      "downloads": 22774,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "mert_model",
        "feature-extraction",
        "music",
        "audio-classification",
        "custom_code",
        "arxiv:2306.00107",
        "license:cc-by-nc-4.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 23
    },
    {
      "model_id": "jakeBland/wav2vec-vm-finetune",
      "license": null,
      "likes": 9,
      "downloads": 19329,
      "last_modified": "None",
      "tags": [
        "transformers",
        "tensorboard",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "generated_from_trainer",
        "speech-recognition",
        "voicemail-detection",
        "en",
        "base_model:facebook/wav2vec2-xls-r-300m",
        "base_model:finetune:facebook/wav2vec2-xls-r-300m",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 24
    },
    {
      "model_id": "mispeech/dasheng-1.2B",
      "license": null,
      "likes": 3,
      "downloads": 18107,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "dasheng",
        "feature-extraction",
        "audio",
        "audio-classification",
        "custom_code",
        "license:apache-2.0",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 25
    },
    {
      "model_id": "tiantiaf/whisper-large-v3-narrow-accent",
      "license": null,
      "likes": 4,
      "downloads": 17740,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "model_hub_mixin",
        "pytorch_model_hub_mixin",
        "speaker_accent_classification",
        "audio-classification",
        "en",
        "dataset:mozilla-foundation/common_voice_11_0",
        "arxiv:2505.14648",
        "base_model:openai/whisper-large-v3",
        "base_model:finetune:openai/whisper-large-v3",
        "license:openrail",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 26
    },
    {
      "model_id": "tiantiaf/wavlm-large-age-sex",
      "license": null,
      "likes": 5,
      "downloads": 17698,
      "last_modified": "None",
      "tags": [
        "safetensors",
        "model_hub_mixin",
        "pytorch_model_hub_mixin",
        "audio-classification",
        "en",
        "arxiv:2505.14648",
        "base_model:microsoft/wavlm-large",
        "base_model:finetune:microsoft/wavlm-large",
        "license:openrail",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 27
    },
    {
      "model_id": "DunnBC22/wav2vec2-base-Speech_Emotion_Recognition",
      "license": null,
      "likes": 13,
      "downloads": 17314,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "tensorboard",
        "wav2vec2",
        "audio-classification",
        "generated_from_trainer",
        "en",
        "dataset:audiofolder",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 28
    },
    {
      "model_id": "tiantiaf/whisper-large-v3-msp-podcast-emotion-dim",
      "license": null,
      "likes": 1,
      "downloads": 17278,
      "last_modified": "None",
      "tags": [
        "safetensors",
        "model_hub_mixin",
        "pytorch_model_hub_mixin",
        "speech_emotion_recognition",
        "audio-classification",
        "en",
        "arxiv:2505.14648",
        "base_model:openai/whisper-large-v3",
        "base_model:finetune:openai/whisper-large-v3",
        "license:openrail",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 29
    },
    {
      "model_id": "speechbrain/lang-id-commonlanguage_ecapa",
      "license": null,
      "likes": 37,
      "downloads": 17186,
      "last_modified": "None",
      "tags": [
        "speechbrain",
        "audio-classification",
        "embeddings",
        "Language",
        "Identification",
        "pytorch",
        "ECAPA-TDNN",
        "TDNN",
        "CommonLanguage",
        "ar",
        "eu",
        "br",
        "ca",
        "cv",
        "cs",
        "dv",
        "nl",
        "en",
        "eo",
        "et",
        "fr",
        "fy",
        "ka",
        "de",
        "el",
        "cnh",
        "id",
        "ia",
        "it",
        "ja",
        "kab",
        "rw",
        "ky",
        "lv",
        "mt",
        "mn",
        "fa",
        "pl",
        "pt",
        "ro",
        "rm",
        "ru",
        "sah",
        "sl",
        "es",
        "sv",
        "ta",
        "tt",
        "tr",
        "uk",
        "cy",
        "dataset:Urbansound8k",
        "arxiv:2106.04624",
        "license:apache-2.0",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 30
    },
    {
      "model_id": "tiantiaf/whisper-large-v3-msp-podcast-emotion",
      "license": null,
      "likes": 5,
      "downloads": 16779,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "model_hub_mixin",
        "pytorch_model_hub_mixin",
        "speech_emotion_recognition",
        "audio-classification",
        "en",
        "arxiv:2505.14648",
        "base_model:openai/whisper-large-v3",
        "base_model:finetune:openai/whisper-large-v3",
        "license:openrail",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 31
    },
    {
      "model_id": "tiantiaf/whisper-large-v3-voice-quality",
      "license": null,
      "likes": 3,
      "downloads": 16312,
      "last_modified": "None",
      "tags": [
        "safetensors",
        "model_hub_mixin",
        "pytorch_model_hub_mixin",
        "audio-classification",
        "en",
        "dataset:ajd12342/paraspeechcaps",
        "arxiv:2505.14648",
        "base_model:openai/whisper-large-v3",
        "base_model:finetune:openai/whisper-large-v3",
        "license:openrail",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 32
    },
    {
      "model_id": "tiantiaf/whisper-large-v3-broad-accent",
      "license": null,
      "likes": 1,
      "downloads": 16229,
      "last_modified": "None",
      "tags": [
        "safetensors",
        "model_hub_mixin",
        "pytorch_model_hub_mixin",
        "audio-classification",
        "en",
        "dataset:mozilla-foundation/common_voice_11_0",
        "arxiv:2505.14648",
        "base_model:openai/whisper-large-v3",
        "base_model:finetune:openai/whisper-large-v3",
        "license:openrail",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 33
    },
    {
      "model_id": "tiantiaf/whisper-large-v3-speech-flow",
      "license": null,
      "likes": 1,
      "downloads": 16214,
      "last_modified": "None",
      "tags": [
        "safetensors",
        "model_hub_mixin",
        "pytorch_model_hub_mixin",
        "audio-classification",
        "en",
        "arxiv:2505.14648",
        "base_model:openai/whisper-large-v3",
        "base_model:finetune:openai/whisper-large-v3",
        "license:openrail",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 34
    },
    {
      "model_id": "bookbot/distil-ast-audioset",
      "license": null,
      "likes": 20,
      "downloads": 14852,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "tensorboard",
        "safetensors",
        "audio-spectrogram-transformer",
        "audio-classification",
        "generated_from_trainer",
        "en",
        "arxiv:2104.01778",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 35
    },
    {
      "model_id": "alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech",
      "license": null,
      "likes": 46,
      "downloads": 14563,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "generated_from_trainer",
        "dataset:librispeech_asr",
        "base_model:facebook/wav2vec2-xls-r-300m",
        "base_model:finetune:facebook/wav2vec2-xls-r-300m",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 36
    },
    {
      "model_id": "superb/hubert-base-superb-er",
      "license": null,
      "likes": 22,
      "downloads": 13288,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "hubert",
        "audio-classification",
        "speech",
        "audio",
        "en",
        "dataset:superb",
        "arxiv:2105.01051",
        "license:apache-2.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 37
    },
    {
      "model_id": "Jzuluaga/accent-id-commonaccent_ecapa",
      "license": null,
      "likes": 17,
      "downloads": 11195,
      "last_modified": "None",
      "tags": [
        "speechbrain",
        "audio-classification",
        "embeddings",
        "Accent",
        "Identification",
        "pytorch",
        "ECAPA-TDNN",
        "TDNN",
        "CommonAccent",
        "en",
        "dataset:CommonVoice",
        "arxiv:2305.18283",
        "arxiv:2106.04624",
        "license:mit",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 38
    },
    {
      "model_id": "superb/hubert-large-superb-er",
      "license": null,
      "likes": 24,
      "downloads": 8702,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "hubert",
        "audio-classification",
        "speech",
        "audio",
        "en",
        "dataset:superb",
        "arxiv:2105.01051",
        "license:apache-2.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 39
    },
    {
      "model_id": "MIT/ast-finetuned-speech-commands-v2",
      "license": null,
      "likes": 17,
      "downloads": 8622,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "audio-spectrogram-transformer",
        "audio-classification",
        "dataset:speech_commands",
        "arxiv:2104.01778",
        "license:bsd-3-clause",
        "model-index",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 40
    },
    {
      "model_id": "superb/wav2vec2-base-superb-ks",
      "license": null,
      "likes": 16,
      "downloads": 8616,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "wav2vec2",
        "audio-classification",
        "speech",
        "audio",
        "en",
        "dataset:superb",
        "arxiv:2105.01051",
        "license:apache-2.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 41
    },
    {
      "model_id": "superb/hubert-base-superb-ks",
      "license": null,
      "likes": 8,
      "downloads": 8264,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "hubert",
        "audio-classification",
        "speech",
        "audio",
        "en",
        "dataset:superb",
        "arxiv:2105.01051",
        "license:apache-2.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 42
    },
    {
      "model_id": "dima806/music_genres_classification",
      "license": null,
      "likes": 37,
      "downloads": 7384,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "base_model:facebook/wav2vec2-base-960h",
        "base_model:finetune:facebook/wav2vec2-base-960h",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 43
    },
    {
      "model_id": "superb/hubert-base-superb-sid",
      "license": null,
      "likes": 1,
      "downloads": 7229,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "hubert",
        "audio-classification",
        "speech",
        "audio",
        "en",
        "dataset:superb",
        "arxiv:2105.01051",
        "license:apache-2.0",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 44
    },
    {
      "model_id": "facebook/mms-lid-4017",
      "license": null,
      "likes": 12,
      "downloads": 7205,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "mms",
        "ab",
        "af",
        "ak",
        "am",
        "ar",
        "as",
        "av",
        "ay",
        "az",
        "ba",
        "bm",
        "be",
        "bn",
        "bi",
        "bo",
        "sh",
        "br",
        "bg",
        "ca",
        "cs",
        "ce",
        "cv",
        "ku",
        "cy",
        "da",
        "de",
        "dv",
        "dz",
        "el",
        "en",
        "eo",
        "et",
        "eu",
        "ee",
        "fo",
        "fa",
        "fj",
        "fi",
        "fr",
        "fy",
        "ff",
        "ga",
        "gl",
        "gn",
        "gu",
        "zh",
        "ht",
        "ha",
        "he",
        "hi",
        "hu",
        "hy",
        "ig",
        "ia",
        "ms",
        "is",
        "it",
        "jv",
        "ja",
        "kn",
        "ka",
        "kk",
        "kr",
        "km",
        "ki",
        "rw",
        "ky",
        "ko",
        "kv",
        "lo",
        "la",
        "lv",
        "ln",
        "lt",
        "lb",
        "lg",
        "mh",
        "ml",
        "mr",
        "mk",
        "mg",
        "mt",
        "mn",
        "mi",
        "my",
        "nl",
        "no",
        "ne",
        "ny",
        "oc",
        "om",
        "or",
        "os",
        "pa",
        "pl",
        "pt",
        "ps",
        "qu",
        "ro",
        "rn",
        "ru",
        "sg",
        "sk",
        "sl",
        "sm",
        "sn",
        "sd",
        "so",
        "es",
        "sq",
        "su",
        "sv",
        "sw",
        "ta",
        "tt",
        "te",
        "tg",
        "tl",
        "th",
        "ti",
        "ts",
        "tr",
        "uk",
        "vi",
        "wo",
        "xh",
        "yo",
        "zu",
        "za",
        "dataset:google/fleurs",
        "arxiv:2305.13516",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 45
    },
    {
      "model_id": "mtg-upf/discogs-maest-30s-pw-129e",
      "license": null,
      "likes": 3,
      "downloads": 5568,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "audio-spectrogram-transformer",
        "audio-classification",
        "arxiv:2309.16418",
        "arxiv:1910.09700",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 46
    },
    {
      "model_id": "awsaf49/sonics-spectttra-alpha-120s",
      "license": null,
      "likes": 0,
      "downloads": 4863,
      "last_modified": "None",
      "tags": [
        "pytorch",
        "deepfake",
        "audio_classification",
        "fake_song_detection",
        "music",
        "song",
        "audio-classification",
        "en",
        "dataset:awsaf49/sonics",
        "arxiv:2408.14080",
        "license:mit",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 47
    },
    {
      "model_id": "seba3y/whisper-tiny",
      "license": null,
      "likes": 0,
      "downloads": 4346,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "whisper",
        "audio-classification",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 48
    },
    {
      "model_id": "anton-l/wav2vec2-random-tiny-classifier",
      "license": null,
      "likes": 2,
      "downloads": 3565,
      "last_modified": "None",
      "tags": [
        "transformers",
        "pytorch",
        "wav2vec2",
        "audio-classification",
        "endpoints_compatible",
        "deploy:azure",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 49
    },
    {
      "model_id": "MelodyMachine/Deepfake-audio-detection-V2",
      "license": null,
      "likes": 17,
      "downloads": 3096,
      "last_modified": "None",
      "tags": [
        "transformers",
        "safetensors",
        "wav2vec2",
        "audio-classification",
        "generated_from_trainer",
        "dataset:audiofolder",
        "base_model:mo-thecreator/Deepfake-audio-detection",
        "base_model:finetune:mo-thecreator/Deepfake-audio-detection",
        "license:apache-2.0",
        "model-index",
        "endpoints_compatible",
        "region:us"
      ],
      "pipeline_tag": "audio-classification",
      "task_id": "audio-classification",
      "rank_in_task": 50
    }
  ],
  "stats": {
    "tasks_processed": 2,
    "total_models": 100,
    "unique_models": 100
  }
}