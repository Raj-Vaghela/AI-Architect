# ðŸ’¬ How to Chat with Stack8s AI Architect

There are **4 easy ways** to chat with your AI Architect!

---

## Prerequisites

**Make sure your server is running:**

```powershell
# Terminal 1 - Start the server
cd E:\Stack8s\backend
.\venv\Scripts\Activate.ps1
python -m app.main
```

**You should see:**
```
INFO:     Uvicorn running on http://0.0.0.0:8000
INFO:     Started server process
INFO:     Application startup complete.
```

Keep this terminal running!

---

## Option 1: Web Browser Chat (Most Beautiful!) ðŸŽ¨â­

**Best for:** Visual, user-friendly experience

1. Make sure server is running (see above)
2. Open `backend/scripts/chat.html` in your browser:
   - Double-click the file, OR
   - Right-click â†’ Open with â†’ Chrome/Edge/Firefox

**Features:**
- âœ¨ Beautiful gradient UI
- ðŸ’¬ Real-time chat interface
- ðŸ“‹ Deployment plan summaries
- ðŸŽ¯ Shows connection status
- ðŸ“± Responsive design

**Example prompts to try:**
```
I need to deploy Llama 70B for inference

Help me train a computer vision model with a $3000 budget

Set up Stable Diffusion XL for image generation

I need GPUs for fine-tuning a language model
```

---

## Option 2: Interactive Python Script (Best for CLI) ðŸ’»â­

**Best for:** Terminal lovers, quick testing

```powershell
# Open a NEW terminal (keep server running in Terminal 1)
cd E:\Stack8s\backend
.\venv\Scripts\Activate.ps1
$env:PYTHONIOENCODING='utf-8'
python scripts\chat.py
```

**Features:**
- ðŸ’¬ Interactive command-line chat
- ðŸ“ Full conversation history
- ðŸ”„ Start new conversations with `new`
- ðŸ“œ View history with `history`
- ðŸšª Exit with `quit` or `exit`

**Screenshot:**
```
================================================================================
  Stack8s AI Architect - Interactive Chat
================================================================================

Starting new conversation...
âœ“ Conversation started (ID: 198e1149...)

Type your messages below. Commands:
  - 'exit' or 'quit' to end chat
  - 'new' to start a new conversation
  - 'history' to see all messages

================================================================================

You: I need to deploy Llama 70B for inference

Thinking...

AI Architect [clarification]:
================================================================================
I need a bit more information to help you best:

1. What is your monthly budget for this deployment?
2. Do you have any specific GPU model preferences or requirements?
3. What regions do you prefer for this deployment?
================================================================================

You: _
```

---

## Option 3: Swagger UI (Best for API Testing) ðŸ”§

**Best for:** Developers, API testing, seeing all endpoints

1. Make sure server is running
2. Open browser: http://localhost:8000/docs

**Steps:**
1. Click **"POST /api/v1/chat/start"**
2. Click **"Try it out"** â†’ **"Execute"**
3. Copy the `conversation_id` from response
4. Click **"POST /api/v1/chat/message"**
5. Click **"Try it out"**
6. Paste your `conversation_id`
7. Type your message
8. Click **"Execute"**
9. See the AI's response!

**Features:**
- ðŸ“š See all API endpoints
- ðŸ§ª Test any endpoint
- ðŸ“„ API documentation
- ðŸ” See request/response formats

---

## Option 4: PowerShell Script Demo ðŸ“œ

**Best for:** Quick demo, automated testing

```powershell
cd E:\Stack8s\backend
.\scripts\chat_example.ps1
```

**What it does:**
1. Starts a conversation
2. Sends a test message
3. Displays the response
4. Shows conversation history

**Example output:**
```
================================
Stack8s AI Architect - Chat Demo
================================

Step 1: Starting conversation...
âœ“ Conversation ID: 198e1149-8a0c-41b6-931b-b208a6a0b5c6

Step 2: Sending message...

AI Response Type: clarification

--- AI Response ---
I need a bit more information to help you best:

1. What is your monthly budget for this deployment?
2. Do you have any specific GPU model preferences?
-------------------

Step 3: Fetching conversation history...
âœ“ Total messages: 2
```

---

## Quick Comparison

| Method | Best For | Difficulty | Visual |
|--------|----------|-----------|--------|
| **Web Browser** | Everyone | â­ Easiest | âœ… Beautiful |
| **Python Script** | CLI users | â­â­ Easy | ðŸ“ Text |
| **Swagger UI** | Developers | â­â­ Easy | âœ… Good |
| **PowerShell** | Quick demo | â­â­â­ Medium | ðŸ“ Text |

---

## Example Conversations

### Example 1: LLM Inference
```
You: I need to deploy Llama 70B for inference
AI: [Asks clarifying questions about budget, region, provider]

You: Budget is $5000/month, prefer AWS
AI: [Generates deployment plan with GPU recommendations, 
     model info, K8s stack, cost breakdown]
```

### Example 2: Computer Vision
```
You: Help me train a computer vision model for object detection

AI: [Asks about budget, GPU requirements, dataset size]

You: Budget $3000/month, need 2 GPUs with 24GB VRAM each

AI: [Generates deployment plan]:
  âœ“ GPU: runpod RTX A5000 (2x 24GB) - $584/mo
  âœ“ Models: facebook/detr-resnet-50, etc.
  âœ“ K8s: MLflow, Kubeflow, Prometheus, Grafana
  âœ“ Steps: 5 deployment steps
  âœ“ Cost: $634/month breakdown
```

### Example 3: Stable Diffusion
```
You: Set up Stable Diffusion XL for image generation

AI: [Asks about budget, provider, scale requirements]

You: Budget $2000/month, need production-ready setup

AI: [Generates deployment plan]:
  âœ“ GPU: L40S or A40 instances
  âœ“ Models: Stable Diffusion XL variants
  âœ“ K8s: vLLM/Triton for serving, Redis, NGINX
  âœ“ Architecture for production inference
```

---

## Troubleshooting

### "Server not running" error

**Solution:**
```powershell
cd E:\Stack8s\backend
.\venv\Scripts\Activate.ps1
python -m app.main
```

### Web browser says "Cannot connect"

**Solution:**
- Check server is running at http://localhost:8000
- Try opening http://localhost:8000/health in browser
- If that works, refresh the chat page

### Python script encoding errors

**Solution:**
```powershell
$env:PYTHONIOENCODING='utf-8'
python scripts\chat.py
```

### PowerShell script won't run

**Solution:**
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
.\scripts\chat_example.ps1
```

---

## Tips for Best Results

### 1. Be Specific
âŒ "I need GPUs"
âœ… "I need to deploy Llama 70B for inference with a budget of $3000/month"

### 2. Provide Context
âœ… "I want to train a computer vision model for object detection. 
    I have a dataset of 100K images and need at least 24GB VRAM per GPU."

### 3. Mention Constraints
âœ… "Budget is $2000/month, prefer AWS, need HIPAA compliance"

### 4. Ask Follow-ups
The AI maintains conversation context, so you can:
```
You: I need to deploy an LLM
AI: [Asks questions]
You: Budget is $5000/month
AI: [More questions]
You: Prefer GCP, need multi-region
AI: [Generates plan]
You: What if I reduce budget to $3000?
AI: [Adjusts recommendations]
```

---

## What the AI Can Help With

âœ… **GPU Selection**
- Find best GPU instances across providers
- Compare prices and performance
- Get cost estimates

âœ… **Model Recommendations**
- Search 30,403 HuggingFace models
- Get license information
- Match models to your task

âœ… **Kubernetes Stack**
- Recommend ML frameworks
- Suggest observability tools
- Design complete infrastructure

âœ… **Deployment Plans**
- Step-by-step deployment
- Cost breakdowns
- Architecture decisions
- Tradeoff analysis

---

## Advanced Usage

### Save Conversation for Later

```powershell
# Get conversation history
curl http://localhost:8000/api/v1/chat/YOUR_CONVERSATION_ID > my_conversation.json
```

### Use Different Models

Edit `backend/.env.local`:
```env
# Use better model for higher quality
OPENAI_CHAT_MODEL=gpt-4o  # Instead of gpt-4o-mini
```

### Debug Mode

Check server logs in Terminal 1 to see:
- What tools are being called
- What data is being retrieved
- How decisions are made

---

## Quick Start (TL;DR)

**Fastest way to start chatting:**

```powershell
# Terminal 1
cd E:\Stack8s\backend
.\venv\Scripts\Activate.ps1
python -m app.main

# Terminal 2
cd E:\Stack8s\backend
.\venv\Scripts\Activate.ps1
$env:PYTHONIOENCODING='utf-8'
python scripts\chat.py
```

**Or just double-click:**
`backend/scripts/chat.html`

---

**Happy Chatting! ðŸš€**

Need help? Check:
- `README.md` - Full documentation
- `QUICKSTART.md` - Setup guide
- `docs/PRD_ALIGNMENT_REPORT.md` - Feature details

